1. 범주형 데이터를 어떻게 인코딩할 건지 고민해보기
- 다 원핫 인코딩해서 PCA로 차원 축소할 건지 vs 주요 피처만 원핫 인코딩하고 나머지는 타겟인코딩할 건지
2. 피처 스케일링 고민해보기
- minmax VS standard

<br>
<br>
       
😵‍💫 **회귀분석에서의 조건수** (https://mkjjo.github.io/python/2019/01/10/scaler.html)
        
조건수가 크면 약간의 오차만 있어도 해가 전혀 다른 값을 가짐. 따라서 조건수가 크면 회귀분석을 사용한 예측값도 오차가 커지게 됨!*
        
1. 변수들의 단위 차이로 인해 숫자의 스케일이 크게 달라지는 경우. 이 경우에는 스케일링(scaling)으로 해결
    |종류|설명|
    |----|-------|
    |StandardScaler|기본 스케일, 평균과 표준편차 사용|
    |MinMaxScaler|최대/최솟값이 각각 1,0이 되도록 스케일링|
    |MaxAbsScaler|최대절댓값과 0이 각각 1,0이 되도록 스케일링|
    |RobustScaler|중앙값(median)과 IQR(Interquantile range) 사용, 아웃라이어의 앙상블 최소화|

            
2. 다중 공선성 즉, 상관관계가 큰 독립 변수들이 있는 경우, 이 경우에는 변수 선택이나 PCA를 사용한 차원 축소 등으로 해결
        

<br>
<br>


| StandardScaler
- 평균을 제거하고 데이터를 단위 분산으로 조정
- 이상치가 있다면 평균과 표준편차에 영향을 미쳐 변환된 데이터의 확산은 매우 달라지게 됨

| MinMaxScaler
- 모든 feature 값이 0~1사이에 있도록 데이터를 재조정
- 이상치가 있는 경우 변환된 값이 매우 좁은 범위로 압축될 수 있음 (아웃라이어의 존재에 매우 민감함)

| MaxAbsScaler
- 절대값이 0~1사이에 매핑되도록 함. 즉 -1~1 사이로 재조정
- 양수 데이터로만 구성된 특징 데이터셋에서는 MinMaxScaler와 유사하게 동작하며, 큰 이상치에 민감할 수 있음

| **RobustScaler**
- 아웃라이어의 영향을 최소화한 기법이다. `중앙값(median)과 IQR(interquartile range)`을 사용하기 때문에 StandardScaler와 비교해보면 **표준화 후 동일한 값을 더 넓게 분포** 시키고 있음을 확인 할 수 있음
    
    → 아웃라이어 제거가 선행되어야 함!!